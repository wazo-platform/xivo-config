#!/usr/bin/python
# -*- coding: utf-8 -*-

__copyright__ = 'Copyright (C) 2012 Avencall'
__license__ = """
    Copyright (c) 2012  Avencall

    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation; either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
"""

import os, subprocess, traceback
import sys
from sys import exit, stderr
import urllib2
from urllib2 import URLError, HTTPError
import json
import fnmatch
import time
import gzip
import contextlib
import re
from optparse import OptionParser


DEBUG = False
IP_XIVO = "127.0.0.1"
FILE_DELIMITERS = '|'
DEFAULT_OUT_FILE = "/tmp/insert_file_pg_cpoy_%s" % time.strftime('%Y%m%d%H%M%S', time.localtime())

URL_QUEUE = "https://%s/callcenter/json.php/private/settings/queues/" % IP_XIVO
URL_AGENT = "https://%s/callcenter/json.php/private/settings/agents/" % IP_XIVO

LIST_QUEUE = set()
LIST_AGENT = set()

COMMAND_COPY = "COPY queue_log (time,callid,queuename,agent,event,data1,data2,data3,data4,data5) " \
               "FROM '%s' DELIMITERS '%s' CSV" % (DEFAULT_OUT_FILE, FILE_DELIMITERS)


def populate_data_queue(name):
    return {"queuefeatures":
                {
                    "name": name,
                    "context": "default",
                    "number": "",
                    "timeout": 0
                },
            "queue":
                {
                    "timeoutpriority": "app",
                    "min-announce-frequency": 60,
                    "announce-position": "yes",
                    "announce-position-limit": 5
                }
            }


def populate_data_agent(firtname, lastname, number):
    return {"agentfeatures":
                {
                    "firstname": firtname,
                    "lastname": lastname,
                    "context": "default",
                    "number": number,
                    "numgroup": 1,
                    "autologoff": 0,
                    "ackcall": "no",
                    "wrapuptime": 0,
                    "acceptdtmf": "#",
                    "enddtmf": "*"
                },
            "agentoptions":
                {
                    "maxlogintries": 3
                }
            }


def _limit(count):
   """
   decorator that limit the number of elements returned by a generator
   """
   def aux(fun):
       def aux2(*args, **kwargs):
           n = count
           it = fun(*args, **kwargs)
           while n:
               yield it.next()
               n -= 1
       return aux2
   return aux


def _open_file(file):
    if file.endswith('.gz'):
        return contextlib.closing(gzip.open(file))
    else:
        return open(file)


#@_limit(50000)
def readlines(directory):
    print 'Directory process: %s' % directory
    for file in os.listdir(directory):
        print 'File process: %s' % file
        abs_file = os.path.join(directory, file)
        with _open_file(abs_file) as fobj:
            nb_line = 0
            for line in fobj:
                nb_line += 1
                yield line
        print '%s entries found in %s.' % (nb_line, file)


def traitmentline(line, separator='|'):
    rs = line.rstrip().split(separator)
    while len(rs) <= 10:
        rs.append('')
    return rs[:10]


def request_http(url, data=None):
    try:
        if data is not None:
            data = data.replace(' ', '').replace('\n', '')
        req = urllib2.Request(url, data)
        return urllib2.urlopen(req)
    except HTTPError, e:
        if DEBUG:
            print 'error during processing url:', url, 'code:', e.code, ' response:', e.read()
    except URLError, e:
        if DEBUG:
            print 'error during processing url:', url, 'code:', e.code, ' response:', e.read()


def exec_ws():
    for q in LIST_QUEUE:
        fobj = request_http('%s?act=search&search=%s' % (URL_QUEUE, q))
        if hasattr(fobj, 'code'):
            if fobj.code == 204:
                if DEBUG:
                    print 'Queue %s not found.' % (q)
                data = json.dumps(populate_data_queue(q))
                fobj = request_http('%s?act=add' % (URL_QUEUE), data)
                if DEBUG:
                    print 'Create Queue %s, response: %s' % (q, fobj.code)
            else:
                if DEBUG:
                    print 'Queue %s found.' % (q)
    for a in LIST_AGENT:
        m = re.search("agent/([0-9]{4})", a, re.I)
        if m is not None:
            number = m.group(1)
            data = json.dumps(populate_data_agent(a, '', number))
            fobj = request_http('%s?act=view&id=%s' % (URL_AGENT, number))
            if hasattr(fobj, 'code'):
                if fobj.code == 204:
                    if DEBUG:
                        print 'Agent %s not found.' % (number)
                    fobj = request_http('%s?act=add' % (URL_AGENT), data)
                    if hasattr(fobj, 'code') and fobj.code == 200:
                        if DEBUG:
                            print 'Agent %s successfully created' % (number)
                else:
                    if DEBUG:
                        print 'Agent %s found.' % (number)
                    #agent need update but edit method is not possible in webi via webservices.
                    #agentinfo = json.load(fobj.read())
                    #agentid = agentinfo['agentfeatures']['id']
                    #fobj = request_http('%s&act=edit&id=%d' % (base_url_agent), data, agentid)
                    fobj = request_http('%s?act=add' % (URL_AGENT), data)
                    if hasattr(fobj, 'code') and fobj.code == 200:
                        if DEBUG:
                            print 'Agent %s successfully created' % (number)


def main(directory):
    if not os.access(directory, os.R_OK):
        raise "Can't open directory %s" % directory
    with open(DEFAULT_OUT_FILE, 'w') as fobj:
        total_line_nb = 0
        for line in readlines(directory):
            linet = traitmentline(line)
            total_line_nb += 1
            datetime = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime((int(linet[0]))))
            lineoutput = '%s%s' % (datetime, FILE_DELIMITERS) + FILE_DELIMITERS.join(linet[1:]) + '\n'
            fobj.write(lineoutput)
            # build list queue
            LIST_QUEUE.add(linet[2])
            # build list agent
            LIST_AGENT.add(linet[3])

    print 'Total: %s lines found for processing' % total_line_nb
    print

    exec_ws()

    try:
        if DEBUG:
            print 'sudo', '-H', '-u', 'postgres' , 'psql', 'asterisk', '-c', COMMAND_COPY
        subprocess.check_call(['sudo', '-H', '-u', 'postgres' , 'psql' , 'asterisk', '-c', COMMAND_COPY])
    except (OSError, subprocess.CalledProcessError), e:
        traceback.print_exc()


if __name__ == '__main__':
    parser = OptionParser()
    parser.add_option('-d', '--debug', action='store_true', dest='debug',
                      help='mode debug')
    parser.add_option('-o', '--outfile', action='store_true', dest='output_filename',
                      help='choose out file', default=DEFAULT_OUT_FILE)
    opts, args = parser.parse_args()
    if opts.debug:
        DEBUG = True
    if opts.output_filename:
        DEFAULT_OUT_FILE = opts.output_filename
    if len(args) != 1:
        print >> sys.stderr, "usage: %s -d -o <output_filename> <directory>" % ("./qlogtopostgres")
        raise sys.exit(1)
    else:
        main(args[0])
